{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report,f1_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075107ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/csv/Suicide_Detection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3052919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "data.shape\n",
    "data = data.rename(columns={\"text\": \"text\", \"class\": \"label\"})\n",
    "data = data[[\"text\", \"label\"]].dropna()\n",
    "data.isnull().sum()\n",
    "print(data.label.value_counts())\n",
    "# Remove exact duplicates\n",
    "data = data.drop_duplicates(subset=[\"text\"])\n",
    "\n",
    "# Strip whitespace\n",
    "data[\"text\"] = data[\"text\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f0ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"label\", data=data, palette=\"Set2\")\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40be913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "for label in data[\"label\"].unique():\n",
    "    text_data = \" \".join(data[data[\"label\"] == label][\"text\"])\n",
    "    wc = WordCloud(width=800, height=400, background_color=\"white\").generate(text_data)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Word Cloud for class: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0a7758",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text_length\"] = data[\"text\"].str.len()\n",
    "plt.hist(data[\"text_length\"], bins=50, edgecolor=\"black\")\n",
    "plt.title(\"Text Length Distribution\")\n",
    "plt.xlabel(\"Length of text\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2662941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "all_words = \" \".join(data[\"text\"]).split()\n",
    "counter = Counter(all_words)\n",
    "common_words = counter.most_common(20)\n",
    "\n",
    "words, counts = zip(*common_words)\n",
    "plt.bar(words, counts)\n",
    "plt.xticks(rotation=75)\n",
    "plt.title(\"Top 20 Most Frequent Words\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818718b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_per_class = {\n",
    "    label: len(set(\" \".join(data[data[\"label\"]==label][\"text\"]).split()))\n",
    "    for label in data[\"label\"].unique()\n",
    "}\n",
    "plt.bar(vocab_per_class.keys(), vocab_per_class.values())\n",
    "plt.title(\"Vocabulary Size per Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be172a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    data, test_size=0.2, random_state=42, stratify=data[\"label\"]\n",
    ")\n",
    "\n",
    "print(train_df.label.value_counts(normalize=True))\n",
    "print(test_df.label.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256ebfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, title=\"\"):\n",
    "    print(title)\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Macro F1:\", f1_score(y_true, y_pred, average=\"macro\"))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Set2\")\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a04a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_svm = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        ngram_range=(1,2),       \n",
    "        min_df=2,                 # ignore rare tokens\n",
    "        max_df=0.95,              # ignore overly common tokens\n",
    "        sublinear_tf=True,        # log-scale term frequency\n",
    "        strip_accents=\"unicode\"   # normalize accents\n",
    "    )),\n",
    "    (\"clf\", LinearSVC(C=1.0))\n",
    "])\n",
    "\n",
    "tfidf_svm.fit(train_df.text, train_df.label)\n",
    "pred_svm = tfidf_svm.predict(test_df.text)\n",
    "evaluate(test_df.label, pred_svm, title=\"TF-IDF + LinearSVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6abfce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_lr = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.95, sublinear_tf=True, strip_accents=\"unicode\")),\n",
    "    (\"clf\", LogisticRegression(max_iter=3000, C=2.0, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "tfidf_nb = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.95)),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "tfidf_lr.fit(train_df.text, train_df.label)\n",
    "pred_lr = tfidf_lr.predict(test_df.text)\n",
    "evaluate(test_df.label, pred_lr, title=\"TF-IDF + LogisticRegression\")\n",
    "\n",
    "tfidf_nb.fit(train_df.text, train_df.label)\n",
    "pred_nb = tfidf_nb.predict(test_df.text)\n",
    "evaluate(test_df.label, pred_nb, title=\"TF-IDF + MultinomialNB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1308c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the pipeline (TF-IDF + LinearSVM)\n",
    "joblib.dump(tfidf_svm, \"tfidf_svm.pkl\")\n",
    "print(\"Model saved as tfidf_svm.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
